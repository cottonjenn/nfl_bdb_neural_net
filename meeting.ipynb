{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFL Big Data Bowl - LSTM with `x_next`, `y_next` and `frame` column\n",
        "\n",
        "**Goal**: Predict `(x_next, y_next)` using **only pre-snap frames** (`frame == \"pre\"`)\n",
        "\n",
        "- One DataFrame\n",
        "- Uses your existing `x_next`, `y_next`\n",
        "- **No NaN leakage** from post-snap kinematics\n",
        "- Masking for variable sequence lengths\n",
        "- Ready for full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q tensorflow scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load your data (replace with your actual path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to_predict = pd.read_csv('your_processed_data.csv')\n",
        "# For demo, we'll assume it's already loaded\n",
        "# to_predict.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Add `frame` column (pre/post snap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace 'is_snap' with your actual snap indicator column\n",
        "to_predict[\"frame\"] = np.where(to_predict[\"is_snap\"] == 1, \"pre\", \"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define features and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [\n",
        "    \"x\", \"y\", \"s\", \"a\", \"dir\", \"o\",\n",
        "    \"play_direction_num\",\n",
        "    \"player_position_WR\", \"player_position_RB\", \"player_position_QB\",\n",
        "    \"player_role_Targeted\", \"player_role_Passer\", \"player_role_Def\",\n",
        "    \"ball_land_x\", \"ball_land_y\"\n",
        "]\n",
        "\n",
        "target_cols = [\"x_next\", \"y_next\"]  # Already in your DF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build pre-snap → (x_next, y_next) sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def build_pre_target_sequences(df, feature_cols, target_cols, max_pre_len=96):\n",
        "#     X_list, y_list, mask_list = [], [], []\n",
        "\n",
        "#     for (game_id, play_id, nfl_id), grp in df.groupby([\"game_id\", \"play_id\", \"nfl_id\"]):\n",
        "#         pre = grp[grp[\"frame\"] == \"pre\"].sort_values(\"frame_id_total\")\n",
        "#         if len(pre) == 0:\n",
        "#             continue\n",
        "\n",
        "#         X_seq = pre[feature_cols].values[-max_pre_len:]\n",
        "#         y_seq = pre[target_cols].values[-max_pre_len:]\n",
        "\n",
        "#         X_list.append(X_seq)\n",
        "#         y_list.append(y_seq)\n",
        "#         mask_list.append(np.ones(len(X_seq)))\n",
        "\n",
        "#     X_pad = pad_sequences(X_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "#     y_pad = pad_sequences(y_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "#     mask  = pad_sequences(mask_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "\n",
        "#     return X_pad, y_pad, mask\n",
        "\n",
        "# SEQ_PRE_LEN = 96\n",
        "# X_pre, y_tgt, pre_mask = build_pre_target_sequences(to_predict, feature_cols, target_cols, SEQ_PRE_LEN)\n",
        "\n",
        "# print(\"X_pre:\", X_pre.shape)\n",
        "# print(\"y_tgt:\", y_tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_pre_target_sequences(df, feature_cols, target_cols, max_pre_len=96):\n",
        "    \"\"\"\n",
        "    Input : pre-snap rows only (frame == \"pre\")\n",
        "    Output: X (features t-95 … t) → y (x_next/y_next at t+1 … t+96)\n",
        "    \"\"\"\n",
        "    X_list, y_list, mask_list = [], [], []\n",
        "\n",
        "    for (game_id, play_id, nfl_id), grp in df.groupby([\"game_id\", \"play_id\", \"nfl_id\"]):\n",
        "        pre = grp[grp[\"frame\"] == \"pre\"].sort_values(\"frame_id_total\")\n",
        "\n",
        "        # ---- NEED AT LEAST 2 ROWS (one for X, one for y) ----\n",
        "        if len(pre) < 2:\n",
        "            continue\n",
        "\n",
        "        # ---- FEATURES: all rows except the LAST pre-snap ----\n",
        "        X_seq = pre[feature_cols].iloc[:-1].values\n",
        "        # ---- TARGETS : all rows except the FIRST pre-snap (shifted) ----\n",
        "        y_seq = pre[target_cols].iloc[1:].values\n",
        "\n",
        "        # ---- Optional: drop any row where target is NaN ----\n",
        "        valid_idx = np.where(~np.isnan(y_seq).any(axis=1))[0]\n",
        "        if len(valid_idx) == 0:\n",
        "            continue\n",
        "        X_seq = X_seq[valid_idx]\n",
        "        y_seq = y_seq[valid_idx]\n",
        "\n",
        "        # ---- Take last `max_pre_len` timesteps ----\n",
        "        X_seq = X_seq[-max_pre_len:]\n",
        "        y_seq = y_seq[-max_pre_len:]\n",
        "\n",
        "        X_list.append(X_seq)\n",
        "        y_list.append(y_seq)\n",
        "        mask_list.append(np.ones(len(X_seq)))\n",
        "\n",
        "    # ---- PAD ----\n",
        "    X_pad = pad_sequences(X_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "    y_pad = pad_sequences(y_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "    mask  = pad_sequences(mask_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "\n",
        "    return X_pad, y_pad, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Scale only real pre-snap frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "real_frames = X_pre[pre_mask == 1]\n",
        "scaled_real = scaler.fit_transform(real_frames)\n",
        "\n",
        "X_scaled = X_pre.copy()\n",
        "X_scaled[pre_mask == 1] = scaled_real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train/val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx_train, idx_val = train_test_split(np.arange(X_scaled.shape[0]), test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val = X_scaled[idx_train], X_scaled[idx_val]\n",
        "y_train, y_val = y_tgt[idx_train], y_tgt[idx_val]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Build LSTM model (one-step-ahead with masking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------\n",
        "# 1. Build sequences (uses the FIXED function above)\n",
        "# --------------------------------------------------------------\n",
        "SEQ_PRE_LEN = 96\n",
        "X_pre, y_tgt, pre_mask = build_pre_target_sequences(to_predict, feature_cols, target_cols, SEQ_PRE_LEN)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. Sanity check (should print \"All good\")\n",
        "# --------------------------------------------------------------\n",
        "assert X_pre.shape[0] == y_tgt.shape[0] == pre_mask.shape[0]\n",
        "print(f\"All good → X: {X_pre.shape}, y: {y_tgt.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. Scale only real frames\n",
        "# --------------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "real_frames = X_pre[pre_mask == 1]\n",
        "scaled = scaler.fit_transform(real_frames)\n",
        "\n",
        "X_scaled = X_pre.copy()\n",
        "X_scaled[pre_mask == 1] = scaled\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. Train/val split (sequence level)\n",
        "# --------------------------------------------------------------\n",
        "idx_train, idx_val = train_test_split(np.arange(X_scaled.shape[0]), test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val = X_scaled[idx_train], X_scaled[idx_val]\n",
        "y_train, y_val = y_tgt[idx_train],   y_tgt[idx_val]\n",
        "\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Val:   {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. Build model\n",
        "# --------------------------------------------------------------\n",
        "def build_model(seq_len, n_feat):\n",
        "    inputs = layers.Input(shape=(seq_len, n_feat))\n",
        "    masked = layers.Masking(mask_value=0.0)(inputs)\n",
        "    lstm   = layers.LSTM(128, return_sequences=True)(masked)\n",
        "    drop   = layers.Dropout(0.2)(lstm)\n",
        "    dense  = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(drop)\n",
        "    out    = layers.TimeDistributed(layers.Dense(2, activation=\"linear\"))(dense)\n",
        "\n",
        "    model = models.Model(inputs, out)\n",
        "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\",\n",
        "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n",
        "    return model\n",
        "\n",
        "model = build_model(SEQ_PRE_LEN, X_train.shape[2])\n",
        "\n",
        "# model = build_model(SEQ_PRE_LEN, X_train.shape[2])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def build_model(seq_len, n_feat):\n",
        "#     inputs = layers.Input(shape=(seq_len, n_feat))\n",
        "#     masked = layers.Masking(mask_value=0.0)(inputs)\n",
        "#     lstm   = layers.LSTM(128, return_sequences=True)(masked)\n",
        "#     drop   = layers.Dropout(0.2)(lstm)\n",
        "#     dense  = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(drop)\n",
        "#     out    = layers.TimeDistributed(layers.Dense(2, activation=\"linear\"))(dense)\n",
        "\n",
        "#     model = models.Model(inputs, out)\n",
        "#     model.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"RootMeanSquaredError\"])\n",
        "#     return model\n",
        "\n",
        "# model = build_model(SEQ_PRE_LEN, X_train.shape[2])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------\n",
        "# 6. TRAIN — THIS WILL NOW WORK\n",
        "# --------------------------------------------------------------\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_test(df_test):\n",
        "    X_pre, _, mask = build_pre_target_sequences(df_test, feature_cols, target_cols, SEQ_PRE_LEN)\n",
        "    real = X_pre[mask == 1]\n",
        "    X_pre[mask == 1] = scaler.transform(real)\n",
        "    return model.predict(X_pre, batch_size=128)\n",
        "\n",
        "# preds = predict_test(test_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
