{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFL Big Data Bowl - LSTM with `x_next`, `y_next` and `frame` column\n",
        "\n",
        "**Goal**: Predict `(x_next, y_next)` using **only pre-snap frames** (`frame == \"pre\"`)\n",
        "\n",
        "- One DataFrame\n",
        "- Uses your existing `x_next`, `y_next`\n",
        "- **No NaN leakage** from post-snap kinematics\n",
        "- Masking for variable sequence lengths\n",
        "- Ready for full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q tensorflow scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load your data (replace with your actual path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to_predict = pd.read_csv('your_processed_data.csv')\n",
        "# For demo, we'll assume it's already loaded\n",
        "# to_predict.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Add `frame` column (pre/post snap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace 'is_snap' with your actual snap indicator column\n",
        "to_predict[\"frame\"] = np.where(to_predict[\"is_snap\"] == 1, \"pre\", \"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define features and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [\n",
        "    \"x\", \"y\", \"s\", \"a\", \"dir\", \"o\",\n",
        "    \"play_direction_num\",\n",
        "    \"player_position_WR\", \"player_position_RB\", \"player_position_QB\",\n",
        "    \"player_role_Targeted\", \"player_role_Passer\", \"player_role_Def\",\n",
        "    \"ball_land_x\", \"ball_land_y\"\n",
        "]\n",
        "\n",
        "target_cols = [\"x_next\", \"y_next\"]  # Already in your DF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build pre-snap â†’ (x_next, y_next) sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_pre_target_sequences(df, feature_cols, target_cols, max_pre_len=96):\n",
        "    X_list, y_list, mask_list = [], [], []\n",
        "\n",
        "    for (game_id, play_id, nfl_id), grp in df.groupby([\"game_id\", \"play_id\", \"nfl_id\"]):\n",
        "        pre = grp[grp[\"frame\"] == \"pre\"].sort_values(\"frame_id_total\")\n",
        "        if len(pre) == 0:\n",
        "            continue\n",
        "\n",
        "        X_seq = pre[feature_cols].values[-max_pre_len:]\n",
        "        y_seq = pre[target_cols].values[-max_pre_len:]\n",
        "\n",
        "        X_list.append(X_seq)\n",
        "        y_list.append(y_seq)\n",
        "        mask_list.append(np.ones(len(X_seq)))\n",
        "\n",
        "    X_pad = pad_sequences(X_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "    y_pad = pad_sequences(y_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "    mask  = pad_sequences(mask_list, maxlen=max_pre_len, dtype=\"float32\", padding=\"pre\", value=0.0)\n",
        "\n",
        "    return X_pad, y_pad, mask\n",
        "\n",
        "SEQ_PRE_LEN = 96\n",
        "X_pre, y_tgt, pre_mask = build_pre_target_sequences(to_predict, feature_cols, target_cols, SEQ_PRE_LEN)\n",
        "\n",
        "print(\"X_pre:\", X_pre.shape)\n",
        "print(\"y_tgt:\", y_tgt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Scale only real pre-snap frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "real_frames = X_pre[pre_mask == 1]\n",
        "scaled_real = scaler.fit_transform(real_frames)\n",
        "\n",
        "X_scaled = X_pre.copy()\n",
        "X_scaled[pre_mask == 1] = scaled_real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train/val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx_train, idx_val = train_test_split(np.arange(X_scaled.shape[0]), test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val = X_scaled[idx_train], X_scaled[idx_val]\n",
        "y_train, y_val = y_tgt[idx_train], y_tgt[idx_val]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Build LSTM model (one-step-ahead with masking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(seq_len, n_feat):\n",
        "    inputs = layers.Input(shape=(seq_len, n_feat))\n",
        "    masked = layers.Masking(mask_value=0.0)(inputs)\n",
        "    lstm   = layers.LSTM(128, return_sequences=True)(masked)\n",
        "    drop   = layers.Dropout(0.2)(lstm)\n",
        "    dense  = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(drop)\n",
        "    out    = layers.TimeDistributed(layers.Dense(2, activation=\"linear\"))(dense)\n",
        "\n",
        "    model = models.Model(inputs, out)\n",
        "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"RootMeanSquaredError\"])\n",
        "    return model\n",
        "\n",
        "model = build_model(SEQ_PRE_LEN, X_train.shape[2])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_test(df_test):\n",
        "    X_pre, _, mask = build_pre_target_sequences(df_test, feature_cols, target_cols, SEQ_PRE_LEN)\n",
        "    real = X_pre[mask == 1]\n",
        "    X_pre[mask == 1] = scaler.transform(real)\n",
        "    return model.predict(X_pre, batch_size=128)\n",
        "\n",
        "# preds = predict_test(test_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
